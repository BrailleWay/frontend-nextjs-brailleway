// =============================
// components/RealtimeBrailinho.jsx
// =============================

"use client";

import { useState, useRef, useEffect, useCallback } from "react";
import { useSession } from "next-auth/react";
import { Button } from "@/components/ui/button";
import { Mic, Phone, Ear, Loader2 } from "lucide-react";
import {
  verificarDisponibilidade,
  confirmarAgendamento,
} from "@/lib/actions";

/*
  üîé  MELHORIAS & DEPURA√á√ÉO
  -------------------------------------
  1. Console logs padronizados com prefixo BRAILINHO ‚û°Ô∏è  facilitam grep.
  2. Exponho status de PeerConnection/DataChannel via logs e UI.
  3. Tratamento robusto de erro na negotiation; reconex√£o autom√°tica opcional.
  4. Convers√£o segura de mensagens (try/catch) + valida√ß√£o de tipos.
  5. Fallback de √°udio resumido para browsers sem getUserMedia.
*/

const tools = [
  {
    type: "function",
    name: "verificar_disponibilidade_medico",
    description:
      "Verifica se h√° um hor√°rio dispon√≠vel para uma consulta com um m√©dico por nome ou especialidade em uma data e hora espec√≠ficas. Sempre deve ser a primeira chamada.",
    parameters: {
      type: "object",
      properties: {
        especialidade: {
          type: "string",
          description: "A especialidade m√©dica desejada, como 'Psicologia'.",
        },
        nome_medico: {
          type: "string",
          description: "O nome do m√©dico desejado.",
        },
        data: {
          type: "string",
          description: "Data da consulta no formato AAAA-MM-DD.",
        },
        hora: {
          type: "string",
          description: "Hora da consulta no formato HH:MM (24h).",
        },
      },
      required: ["data", "hora"],
    },
  },
  {
    type: "function",
    name: "confirmar_agendamento_consulta",
    description:
      "Agenda a consulta ap√≥s confirma√ß√£o verbal. S√≥ deve ser chamada ap√≥s encontrar um hor√°rio dispon√≠vel e o paciente concordar.",
    parameters: {
      type: "object",
      properties: {
        medicoId: {
          type: "number",
          description:
            "O ID num√©rico do m√©dico, retornado pela fun√ß√£o anterior.",
        },
        dataHora: {
          type: "string",
          description: "A data/hora no formato ISO 8601.",
        },
      },
      required: ["medicoId", "dataHora"],
    },
  },
];

export function RealtimeBrailinho() {
  const [connectionStatus, setConnectionStatus] = useState("initializing");
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [pendingConfirm, setPendingConfirm] = useState(null);
  const [pendingArgs, setPendingArgs] = useState(null);
  const { data: session, status: sessionStatus } = useSession();

  const peerConnectionRef = useRef(null);
  const lastAgendamentoArgsRef = useRef(null); // üåü Guardar argumentos v√°lidos = useRef(null);
  const audioPlayerRef = useRef(null);
  const localStreamRef = useRef(null);
  const dataChannelRef = useRef(null);

  // üåê Safe cleanup helper
  const cleanup = useCallback(() => {
    console.info("BRAILINHO ‚û°Ô∏è Cleanup iniciado");
    try {
      if (peerConnectionRef.current) {
        peerConnectionRef.current.close();
        peerConnectionRef.current = null;
      }
      if (localStreamRef.current) {
        localStreamRef.current.getTracks().forEach((t) => t.stop());
        localStreamRef.current = null;
      }
      if (audioPlayerRef.current) {
        audioPlayerRef.current.pause();
        audioPlayerRef.current.srcObject = null;
      }
      if (dataChannelRef.current) {
        dataChannelRef.current.close();
        dataChannelRef.current = null;
      }
    } catch (err) {
      console.error("BRAILINHO ‚ùå Erro no cleanup:", err);
    }
  }, []);

  // üì§ Envia evento JSON para IA
  const sendToAssistant = useCallback((obj) => {
    const dc = dataChannelRef.current;
    if (dc && dc.readyState === "open") {
      dc.send(JSON.stringify(obj));
    } else {
      console.warn("BRAILINHO ‚ö†Ô∏è DataChannel n√£o est√° aberto. Ignorando envio.");
    }
  }, []);

  // -------------------
  // üé§ Escuta confirma√ß√µes do usu√°rio (sim/n√£o)
  // -------------------
  useEffect(() => {
    if (!pendingConfirm || !pendingArgs) return;

    const dc = dataChannelRef.current;
    if (!dc) return;

    const handleUserConfirm = async (event) => {
      let msg;
      try {
        msg = JSON.parse(event.data);
      } catch {
        return;
      }
      if (
        msg.type === "response.audio_transcript.delta" ||
        msg.type === "response.audio_transcript.done"
      ) {
        const fala = (msg.transcript || msg.delta || "")
          .toLowerCase()
          .normalize("NFD")
          .replace(/[^a-zA-Z0-9\s]/g, "");

        if (/(sim|isso|confirm)/.test(fala)) {
          console.info("BRAILINHO ‚úîÔ∏è Confirma√ß√£o detectada:", fala);
          const newArgs = { ...pendingArgs };
          if (pendingConfirm.tipo === "medico") newArgs.nome_medico = pendingConfirm.sugestao;
          if (pendingConfirm.tipo === "especialidade") newArgs.especialidade = pendingConfirm.sugestao;

          setPendingConfirm(null);
          setPendingArgs(null);

          const output = await verificarDisponibilidade(newArgs);
          if (output.disponivel) {
            sendToAssistant({
              type: "conversation.item.create",
              item: {
                type: "function_call_output",
                call_id: pendingConfirm.call_id,
                output: JSON.stringify(output),
              },
            });
            sendToAssistant({ type: "response.create" });
          }
          return;
        }

        if (/(nao|n√£o)/.test(fala)) {
          console.info("BRAILINHO ‚û°Ô∏è Usu√°rio negou confirma√ß√£o:", fala);
          setPendingConfirm(null);
          setPendingArgs(null);
          sendToAssistant({
            type: "conversation.item.create",
            item: {
              type: "message",
              role: "assistant",
              content: [
                {
                  type: "audio",
                  transcript:
                    "Ok, agendamento cancelado. Se quiser tentar outro nome ou especialidade, por favor, fale novamente.",
                },
              ],
            },
          });
        }
      }
    };

    dc.addEventListener("message", handleUserConfirm);
    return () => dc.removeEventListener("message", handleUserConfirm);
  }, [pendingConfirm, pendingArgs, sendToAssistant]);

  // -------------------
  // üîå Conex√£o WebRTC + DataChannel
  // -------------------
  useEffect(() => {
    if (sessionStatus !== "authenticated") {
      setConnectionStatus(sessionStatus === "loading" ? "initializing" : "unauthenticated");
      return;
    }

    let isMounted = true;
    const connect = async () => {
      if (peerConnectionRef.current) return; // already connected
      console.info("BRAILINHO ‚û°Ô∏è Iniciando conex√£o WebRTC");

      try {
        setConnectionStatus("connecting");
        const sessionRes = await fetch("/api/realtime-session");
        if (!sessionRes.ok) throw new Error("Falha ao obter chave de sess√£o");
        const { client_secret } = await sessionRes.json();
        const token = client_secret.value;

        const pc = new RTCPeerConnection();
        peerConnectionRef.current = pc;

        pc.onconnectionstatechange = () => {
          console.debug("BRAILINHO ‚òÜ PeerConnection state:", pc.connectionState);
          if (["failed", "disconnected", "closed"].includes(pc.connectionState)) {
            setConnectionStatus("error");
          }
        };

        const dc = pc.createDataChannel("oai-events");
        dataChannelRef.current = dc;
        dc.onopen = () => console.debug("BRAILINHO ‚òÜ DataChannel aberto");
        dc.onerror = (e) => console.error("BRAILINHO ‚ùå DataChannel erro:", e);
        dc.onclose = () => console.warn("BRAILINHO ‚ö†Ô∏è DataChannel fechado");

        // ----- RECEBE MENSAGENS DA IA
        dc.onmessage = async (event) => {
          console.debug("BRAILINHO ‚á¢ Mensagem IA:", event.data?.slice(0, 200), "...");
          let srvEvt;
          try {
            srvEvt = JSON.parse(event.data);
          } catch {
            return;
          }

          if (
            srvEvt.type === "response.done" &&
            srvEvt.response?.output?.some((i) => i.type === "function_call")
          ) {
            const functionCall = srvEvt.response.output.find((i) => i.type === "function_call");
            const { name, arguments: argStr, id: call_id } = functionCall;
            let args;
            try {
              args = JSON.parse(argStr);
            } catch (e) {
              console.error("BRAILINHO ‚ùå JSON parse argumentos:", e);
              return;
            }

            let output = {};
            try {
              if (name === "verificar_disponibilidade_medico") {
                output = await verificarDisponibilidade(args);
                // Guarda poss√≠veis argumentos de agendamento
                if (output?.proximaAcao?.argumentos) {
                  lastAgendamentoArgsRef.current = output.proximaAcao.argumentos;
                }
                // confirma√ß√£o necess√°ria (nomes similares)
                if (output.precisaConfirmar && output.sugestoes?.length) {
                  setPendingConfirm({
                    tipo: output.precisaConfirmar,
                    sugestao: output.sugestoes[0],
                    call_id,
                  });
                  setPendingArgs(args);

                  const frase =
                    output.sugestoes.length === 1
                      ? `Voc√™ quis dizer ${output.sugestoes[0]}?` +
                        " Por favor, responda sim ou n√£o."
                      : `Encontrei mais de um resultado: ${output.sugestoes.join(", ")}. Qual deseja?`;

                  sendToAssistant({
                    type: "conversation.item.create",
                    item: {
                      type: "message",
                      role: "assistant",
                      content: [{ type: "audio", transcript: frase }],
                    },
                  });
                  return; // aguarda usu√°rio
                }
              } else if (name === "confirmar_agendamento_consulta") {
                // ‚ö†Ô∏è  Prote√ß√£o contra IA alterar argumentos
                const safeArgs = lastAgendamentoArgsRef.current || args;
                if (!lastAgendamentoArgsRef.current) {
                  console.warn("BRAILINHO ‚ö†Ô∏è confirmAgendamento sem cache, usando args vindos da IA");
                } else if (JSON.stringify(args) !== JSON.stringify(safeArgs)) {
                  console.warn("BRAILINHO ‚ö†Ô∏è IA alterou argumentos. Sobrescrevendo pelos seguros:", safeArgs);
                }
                output = await confirmarAgendamento(safeArgs);
              }
            } catch (err) {
              console.error("BRAILINHO ‚ùå Erro na fun√ß√£o server:", err);
              output = { error: err.message || "Erro desconhecido" };
            }

            sendToAssistant({
              type: "conversation.item.create",
              item: { type: "function_call_output", call_id, output: JSON.stringify(output) },
            });
            sendToAssistant({ type: "response.create" });
          }
        };

        // ----- √ÅUDIO OUT
        if (!audioPlayerRef.current) audioPlayerRef.current = new Audio();
        audioPlayerRef.current.autoplay = true;
        pc.ontrack = ({ streams, track }) => {
          setIsSpeaking(true);
          audioPlayerRef.current.srcObject = streams[0];
          track.onended = () => setIsSpeaking(false);
        };

        // ----- √ÅUDIO IN
        let stream;
        try {
          stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        } catch (err) {
          console.error("BRAILINHO ‚ùå getUserMedia falhou:", err);
          setConnectionStatus("error");
          return;
        }
        stream.getTracks().forEach((t) => pc.addTrack(t, stream));
        localStreamRef.current = stream;

        const offer = await pc.createOffer();
        await pc.setLocalDescription(offer);

        const sdpRes = await fetch(
          "https://api.openai.com/v1/realtime?model=gpt-4o-mini-realtime-preview",
          {
            method: "POST",
            headers: {
              "Content-Type": "application/sdp",
              Authorization: `Bearer ${token}`,
            },
            body: offer.sdp,
          }
        );
        if (!sdpRes.ok) throw new Error(`SDP negotiation falhou: ${sdpRes.statusText}`);
        const answer = await sdpRes.text();
        await pc.setRemoteDescription({ type: "answer", sdp: answer });

        // Envia System Prompt
        dc.onopen = () => {
          console.debug("BRAILINHO ‚òÜ DataChannel pronto (onopen override)");
          const systemPrompt = `Sua fun√ß√£o √© um assistente de agendamento de consultas para a plataforma BrailleWay.\nFale em portugu√™s.\n`;
          dc.send(
            JSON.stringify({ type: "session.update", session: { instructions: systemPrompt, tools } })
          );
          setConnectionStatus("connected");
        };
      } catch (err) {
        console.error("BRAILINHO ‚ùå Conex√£o falhou:", err);
        if (isMounted) setConnectionStatus("error");
        cleanup();
      }
    };

    connect();
    return () => {
      isMounted = false;
      cleanup();
    };
  }, [sessionStatus, cleanup]);

  // UI Indicator helper
  const getStatusIndicator = () => {
    switch (connectionStatus) {
      case "initializing":
        return (
          <div className="flex items-center justify-center text-gray-500">
            <Loader2 className="w-4 h-4 mr-2 animate-spin" /> Carregando sess√£o...
          </div>
        );
      case "unauthenticated":
        return <div className="text-gray-500">Fa√ßa login como paciente para usar.</div>;
      case "connecting":
        return (
          <div className="flex items-center justify-center text-yellow-500">
            <Loader2 className="w-4 h-4 mr-2 animate-spin" /> Conectando...
          </div>
        );
      case "connected":
        return isSpeaking ? (
          <div className="flex items-center justify-center text-blue-500">
            <Ear className="w-4 h-4 mr-2 animate-pulse" /> Brailinho falando...
          </div>
        ) : (
          <div className="flex items-center justify-center text-green-500">
            <Mic className="w-4 h-4 mr-2" /> Conectado e ouvindo...
          </div>
        );
      case "error":
        return <span className="text-red-500">Erro na Conex√£o. Tente reabrir.</span>;
      default:
        return <span className="text-gray-500">Desconectado</span>;
    }
  };

  return (
    <div className="flex flex-col items-center justify-center gap-4 p-4 rounded-lg bg-gray-50">
      <h3 className="font-semibold">Brailinho (Voz)</h3>
      <div className="my-2 p-2 border rounded-md min-h-[2.5rem] w-full text-center">
        {getStatusIndicator()}
      </div>
      <Button onClick={cleanup} className="w-full" variant="destructive" disabled={connectionStatus !== "connected" && connectionStatus !== "error"}>
        <Phone className="w-4 h-4 mr-2" /> Encerrar Chamada
      </Button>
    </div>
  );
}

export default RealtimeBrailinho;